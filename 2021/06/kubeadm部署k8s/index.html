<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>kubeadm部署k8s(v1.16) | Outsrkem</title><meta name="generator" content="hexo-theme-ayer"><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/dist/main.css"><link rel="stylesheet" href="/css/fonts/remixicon.css"><link rel="stylesheet" href="/css/custom.css"><script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"><script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script><script src="https://cdn.staticfile.org/mermaid/8.14.0/mermaid.min.js"></script><style>.swal2-styled.swal2-confirm{font-size:1.6rem}</style></head></html><body><div id="app"><main class="content on"><section class="outer"><article id="post-kubeadm部署k8s" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title sea-center" style="border-left:0" itemprop="name"> kubeadm部署k8s(v1.16)</h1></header><div class="article-meta"> <a href="/2021/06/kubeadm%E9%83%A8%E7%BD%B2k8s/index.html" class="article-date"><time datetime="2021-06-09T17:22:51.000Z" itemprop="datePublished">2021-06-10 01:22:51 +08:00</time></a><div class="article-category"> <a class="article-category-link" href="/categories/kubernetes/">kubernetes</a></div><div class="word_count"><span class="post-time"><span class="post-meta-item-icon"><i class="ri-quill-pen-line"></i> <span class="post-meta-item-text">字数统计:</span> <span class="post-count">4.4k</span></span></span> <span class="post-time">&nbsp; | &nbsp;<span class="post-meta-item-icon"><i class="ri-book-open-line"></i> <span class="post-meta-item-text">阅读时长≈</span> <span class="post-count">20 分钟</span></span></span></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="kubeadm部署k8s(v116)">kubeadm部署k8s(v1.16)</h2><h2 id="一、系统初始化操作">一、系统初始化操作</h2><p>系统初始化操作是集群每个节点都要操作的步骤。</p><h3 id="群集环境">群集环境</h3><table><thead><tr><th>IP</th><th>主机名</th><th>说明</th></tr></thead><tbody><tr><td>10.10.10.31</td><td>k8s-master</td><td>master 节点</td></tr><tr><td>10.10.10.32</td><td>k8s-node1</td><td>node 节点</td></tr><tr><td>10.10.10.33</td><td>k8s-node2</td><td>node 节点</td></tr></tbody></table><h3 id="关闭相关防护及swap">关闭相关防护及swap</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 关闭防火墙和 selinux</span><br><span class="line">systemctl stop firewalld &amp;&amp; systemctl disable firewalld</span><br><span class="line">sed -ri &#x27;/^[^#]*SELINUX=/s#=.+$#=disabled#&#x27; /etc/selinux/config &amp;&amp; setenforce 0</span><br><span class="line"></span><br><span class="line"># 关闭 swap (k8s默认不使用 swap，可以指定参数使用 swap)</span><br><span class="line">swapoff -a</span><br><span class="line">yes | cp /etc/fstab /etc/fstab_bak</span><br><span class="line">sed -ri &#x27;/^[^#]*swap/s@^@#@&#x27; /etc/fstab</span><br></pre></td></tr></table></figure><h3 id="配置时间同步">配置时间同步</h3><p>按照该指南配置： <a href="/2023/09/Linux-%E9%85%8D%E7%BD%AE%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5-chronyd%EF%BC%88%E5%AE%A2%E6%88%B7%E7%AB%AF%EF%BC%89/index.html" title="Linux 配置时间同步 chronyd（客户端）">Linux 配置时间同步 chronyd（客户端）</a></p><h3 id="基本配置">基本配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 修改 /etc/hosts 文件</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/hosts</span><br><span class="line">10.10.10.31 k8s-master k8s-master.k8s.com</span><br><span class="line">10.10.10.32 k8s-node1 k8s-node1.k8s.com</span><br><span class="line">10.10.10.33 k8s-node2 k8s-node2.k8s.com</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 修改主机名</span><br><span class="line">master节点:</span><br><span class="line">hostnamectl set-hostname k8s-master</span><br><span class="line"></span><br><span class="line">node1节点：</span><br><span class="line">hostnamectl set-hostname k8s-node1</span><br><span class="line"></span><br><span class="line">node2节点:</span><br><span class="line">hostnamectl set-hostname k8s-node2</span><br></pre></td></tr></table></figure><h3 id="修改-iptables 相关参数">修改 iptables 相关参数</h3><p>CentOS 7 上的一些用户报告了由于iptables被绕过而导致流量路由不正确的问题。创建/etc/sysctl.d/k8s.conf文件，添加如下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">vm.swappiness = 0</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 使配置生效</span><br><span class="line">modprobe br_netfilter</span><br><span class="line">sysctl -p /etc/sysctl.d/k8s.conf</span><br></pre></td></tr></table></figure><h3 id="加载-ipvs 相关模块">加载 ipvs 相关模块</h3><p>由于ipvs已经加入到了内核的主干，所以为 kube-proxy 开启ipvs的前提需要加载以下的内核模块：<br> 在所有的Kubernetes节点执行以下脚本:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF &gt; /etc/sysconfig/modules/ipvs.modules</span><br><span class="line">#!/bin/bash</span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 执行脚本</span><br><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules \</span><br><span class="line">&amp;&amp; bash /etc/sysconfig/modules/ipvs.modules \</span><br><span class="line">&amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span><br></pre></td></tr></table></figure><p>上面脚本创建了/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。 使用如下命令查看是否已经正确加载所需的内核模块。<br> <code>lsmod | grep -e ip_vs -e nf_conntrack_ipv4</code></p><p>接下来还需要确保各个节点上已经安装了ipset软件包。 为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ipset ipvsadm -y</span><br></pre></td></tr></table></figure><h3 id="安装docker">安装Docker</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 安装要求的软件包</span><br><span class="line">yum install yum-utils device-mapper-persistent-data lvm2 -y </span><br><span class="line"></span><br><span class="line"># 添加Docker repository，这里改为国内阿里云repo</span><br><span class="line">yum-config-manager --add-repo http://mirrors.163.com/.help/CentOS7-Base-163.repo</span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"># 安装docker</span><br><span class="line"># 查询docker版本  yum list docker-ce --showduplicates|sort -r</span><br><span class="line"># 安装指定版本</span><br><span class="line">yum install docker-ce-18.09.8 -y  </span><br><span class="line"></span><br><span class="line"># 创建daemon.json配置文件</span><br><span class="line"># 注意，这里这指定了cgroupdriver=systemd，另外由于国内拉取镜像较慢，最后追加了阿里云镜像加速配置。</span><br><span class="line">mkdir /etc/docker</span><br><span class="line">cat &lt;&lt; EOF &gt; /etc/docker/daemon.json </span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">  &quot;storage-opts&quot;: [</span><br><span class="line">    &quot;overlay2.override_kernel_check=true&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://uyah70su.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># mkdir -p /etc/systemd/system/docker.service.d</span><br><span class="line"></span><br><span class="line"># 重启docker服务</span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart docker &amp;&amp; systemctl enable docker</span><br></pre></td></tr></table></figure><h3 id="安装kubeadm、kubelet、kubectl">安装kubeadm、kubelet、kubectl</h3><p>官方安装文档可以参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></p><ul><li>kubelet 在群集中所有节点上运行的核心组件, 用来执行如启动pods和containers等操作。</li><li>kubeadm 引导启动k8s集群的命令行工具，用于初始化 Cluster。</li><li>kubectl 是 Kubernetes 命令行工具。通过 kubectl 可以部署和管理应用，查看各种资源，创建、删除和更新各种组件。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 配置kubernetes.repo的源，由于官方源国内无法访问，这里使用阿里云yum源</span><br><span class="line"></span><br><span class="line">cat &lt;&lt; EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 查询版本安装指定版本</span><br><span class="line"># yum list --showduplicates kubeadm --disableexcludes=kubernetes</span><br><span class="line"></span><br><span class="line"># 在所有节点上安装kubelet、kubeadm 和 kubectl</span><br><span class="line">yum install -y kubelet-1.16.2 kubeadm-1.16.2 kubectl-1.16.2</span><br><span class="line"></span><br><span class="line"># 启动kubelet服务</span><br><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure><h2 id="二、正式部署kubernetes">二、正式部署kubernetes</h2><p>以下操作是分节点操作步骤。</p><h3 id="部署master节点">部署master节点</h3><h4 id="1、生成默认配置文件">1、生成默认配置文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config print init-defaults &gt; kubeadm.yaml</span><br></pre></td></tr></table></figure><p>kubeadm-config.yaml组成部署说明：</p><ul><li>InitConfiguration： 用于定义一些初始化配置，如初始化使用的token以及apiserver地址等</li><li>ClusterConfiguration：用于定义apiserver、etcd、network、scheduler、controller-manager等master组件相关配置项</li><li>KubeletConfiguration：用于定义kubelet组件相关的配置项</li><li>KubeProxyConfiguration：用于定义kube-proxy组件相关的配置项\</li></ul><p>可以看到，在默认的kubeadm-config.yaml文件中只有InitConfiguration、ClusterConfiguration 两部分。我们可以通过如下操作生成另外两部分的示例文件：</p><blockquote><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/breezey/p/11770780.html">https://www.cnblogs.com/breezey/p/11770780.html</a></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成KubeletConfiguration示例文件</span> </span><br><span class="line">kubeadm config print init-defaults --component-configs KubeletConfiguration</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成KubeProxyConfiguration示例文件</span> </span><br><span class="line">kubeadm config print init-defaults --component-configs KubeProxyConfiguration</span><br></pre></td></tr></table></figure><h4 id="2、根据实际情况进行修改">2、根据实际情况进行修改</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 10.10.10.31    # 修改为API Server的地址</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: /var/run/dockershim.sock</span><br><span class="line">  name: k8s-master</span><br><span class="line">  taints:</span><br><span class="line">  - effect: NoSchedule</span><br><span class="line">    key: node-role.kubernetes.io/master</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns:</span><br><span class="line">  type: CoreDNS</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers 	# 修改为阿里云镜像仓库</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.16.2          # 当前版本</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12       # 修改Service的网络，这里使用默认ip</span><br><span class="line">  podSubnet: 10.244.0.0/16          # 修改Pod的网络，这个不指定会导致flannel起不来，这里使用默认ip</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line"># 下面增加的配置，用于设置Kube-proxy使用LVS</span><br><span class="line">---</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">ipvs:</span><br><span class="line">  excludeCIDRs: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  scheduler: &quot;rr&quot;</span><br><span class="line">  strictARP: false</span><br><span class="line">  syncPeriod: 30s</span><br></pre></td></tr></table></figure><blockquote><h4 id="上面使用的是默认etcd，如果使用外部etcd，参照下面配置">上面使用的是默认etcd，如果使用外部etcd，参照下面配置</h4><p><dev><img align="left" src="/images/2021-06/1.png"></dev></p></blockquote><blockquote><h4 id="相关etcd操作">相关etcd操作</h4><p>操作etcd有命令行工具etcdctl，有两个api版本互不兼容的，系统默认的v2版本，kubernetes集群使用的是v3版本，v2版本下是看不到v3版本的数据的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用环境变量定义api版本</span></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">申明etcd相关信息，etcdctl 默认连接的是http://127.0.0.1:2379，因无证书也能访问，建议关闭回环网卡监听。</span></span><br><span class="line">export PATH=/opt/kubernetes/bin:$PATH</span><br><span class="line">export ETCD_ENDPOINTS=https://10.10.10.31:2379,https://10.10.10.32:2379,https://10.10.10.33:2379</span><br><span class="line">export ETCD_CA_FILE=/opt/kubernetes/ssl/ca.pem</span><br><span class="line">export ETCD_cert_FILE=/opt/kubernetes/ssl/etcd.pem</span><br><span class="line">export ETCD_key_FILE=/opt/kubernetes/ssl/etcd-key.pem</span><br><span class="line"> 配置etcdctl别名</span><br><span class="line">alias etcdctl=&quot;etcdctl --endpoints=$ETCD_ENDPOINTS --cacert=$ETCD_CA_FILE --cert=$ETCD_cert_FILE --key=$ETCD_key_FILE&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcd有目录结构类似linux文件系统，获取所有key。</span></span><br><span class="line">etcdctl get / --prefix --keys-only</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询命名空间下所有部署的数据：</span></span><br><span class="line">etcdctl get /registry/deployments/default --prefix --keys-only</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除某个数据</span></span><br><span class="line">etcdctl del /registry/daemonsets/kube-system/kube-proxy</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除所有数据</span></span><br><span class="line">etcdctl del / --prefix</span><br></pre></td></tr></table></figure></blockquote><h4 id="3、执行初始化操作">3、执行初始化操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config kubeadm.yaml --dry-run # 模拟操作</span><br><span class="line">kubeadm init --config kubeadm.yaml</span><br></pre></td></tr></table></figure><p>集群初始化如果遇到问题，可以使用kubeadm reset命令进行清理然后重新执行初始化，该命令会重置整个集群，慎用。</p><p>完整的官方文档可以参考：</p><blockquote><p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a><br> <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/</a></p></blockquote><h3 id="配置-kubectl">配置 kubectl</h3><p>kubectl 是管理 Kubernetes Cluster 的命令行工具， Master 初始化完成后需要做一些配置工作才能使用kubectl，，这里直接配置root用户:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br></pre></td></tr></table></figure><p>普通用户可以参考 kubeadm init 最后提示</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><p>Kubernetes 集群默认需要加密方式访问，以上操作就是将刚刚部署生成的 Kubernetes 集群的安全配置文件保存到当前用户的.kube 目录下，kubectl 默认会使用<code>~/.kube/config</code>文件的授权信息访问 Kubernetes 集群。<br> 如果不这么做的话，我们每次都需要通过 export KUBECONFIG 环境变量告诉 kubectl 这个安全配置文件的位置或者执行kubectl 时指定该文件位置，如 <code>kubectl --kubeconfig=/etc/kubernetes/admin.conf get node</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 启用 kubectl 命令自动补全功能(注销重新登录生效)</span><br><span class="line">yum install -y bash-completion</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><p>查看集群状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl get componentstatuses  (简写  kubectl get cs)</span><br><span class="line">NAME                 AGE</span><br><span class="line">scheduler            &lt;unknown&gt;</span><br><span class="line">controller-manager   &lt;unknown&gt;</span><br><span class="line">etcd-0               &lt;unknown&gt; </span><br></pre></td></tr></table></figure><p>最新版本的kubernetes在执行kubectl get cs时输出内容有一些变化，以前是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># kubectl get componentstatuses</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br></pre></td></tr></table></figure><p>现在变成了：</p><blockquote><p>原因可参考 <a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000020912684">https://segmentfault.com/a/1190000020912684</a></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># kubectl get componentstatuses</span><br><span class="line">NAME                 Age    </span><br><span class="line">controller-manager   &lt;unknown&gt;</span><br><span class="line">scheduler            &lt;unknown&gt;</span><br><span class="line">etcd-0               &lt;unknown&gt;</span><br><span class="line"># 使用如下命令可以输出正常信息</span><br><span class="line">kubectl get cs -o=go-template=&#x27;&#123;&#123;printf &quot;|NAME|STATUS|MESSAGE|\n&quot;&#125;&#125;&#123;&#123;range .items&#125;&#125;&#123;&#123;$name:= .metadata.name&#125;&#125;&#123;&#123;range .conditions&#125;&#125;&#123;&#123;printf &quot;|%s|%s|%s|\n&quot; $name .status .message&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure><p>确认各个组件都处于healthy状态。查看节点状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl get nodes </span><br><span class="line">NAME         STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master   NotReady   master   36m   v1.16.0</span><br><span class="line">[centos@k8s-master ~]# </span><br></pre></td></tr></table></figure><p>可以看到，当前只存在1个master节点，并且这个节点的状态是 NotReady。<br> 使用 kubectl describe 命令来查看这个节点（Node）对象的详细信息、状态和事件（Event）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl describe node k8s-master </span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason                   Age               </span><br><span class="line">----    ------                   ----               - ......</span><br><span class="line">  Normal  Starting                 33m               </span><br><span class="line">  Normal  NodeHasSufficientMemory  33m (x8 over 33m) </span><br><span class="line">  Normal  NodeHasNoDiskPressure    33m (x8 over 33m) </span><br><span class="line">  Normal  NodeHasSufficientPID     33m (x7 over 33m) </span><br><span class="line">  Normal  NodeAllocatableEnforced  33m               </span><br><span class="line">  Normal  Starting                 33m               </span><br></pre></td></tr></table></figure><p>通过 kubectl describe 指令的输出，我们可以看到 NodeNotReady 的原因在于，我们尚未部署任何网络插件，kube-proxy等组件还处于starting状态。<br> 另外，我们还可以通过 kubectl 检查这个节点上各个系统 Pod 的状态，其中，kube-system 是 Kubernetes 项目预留的系统 Pod 的工作空间（Namepsace，注意它并不是 Linux Namespace，它只是 Kubernetes 划分不同工作空间的单位）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl -n kube-system get pod -o wide    </span><br><span class="line">NAME                                 READY   STATUS    RESTARTS  ......</span><br><span class="line">coredns-78d4cf999f-7jdx7             0/1     Pending   0</span><br><span class="line">coredns-78d4cf999f-s6mhk             0/1     Pending   0</span><br><span class="line">etcd-k8s-master                      1/1     Running   0</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running   0</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running   0</span><br><span class="line">kube-proxy-przwf                     1/1     Running   0</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running   0</span><br></pre></td></tr></table></figure><p>可以看到，CoreDNS依赖于网络的 Pod 都处于 Pending 状态，即调度失败。这当然是符合预期的：因为这个 Master 节点的网络尚未就绪。</p><h3 id="部署网络插件">部署网络插件</h3><p>要让 Kubernetes Cluster 能够工作，必须安装 Pod 网络，否则 Pod 之间无法通信。<br> Kubernetes 支持多种网络方案，这里我们使用 flannel</p><p>执行如下命令部署 flannel：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line"># 使用如下清单文件创建</span><br><span class="line">https://gitee.com/Outsrkem/flannel/tree/master/1.16.2</span><br></pre></td></tr></table></figure><p>部署完成后，我们可以通过 kubectl get 重新检查 Pod 的状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl get pod -n kube-system -o wide</span><br><span class="line">NAME                                 READY   STATUS   ......</span><br><span class="line">coredns-78d4cf999f-7jdx7             1/1     Running</span><br><span class="line">coredns-78d4cf999f-s6mhk             1/1     Running</span><br><span class="line">etcd-k8s-master                      1/1     Running</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running</span><br><span class="line">kube-flannel-ds-amd64-lkf2f          1/1     Running</span><br><span class="line">kube-proxy-przwf                     1/1     Running</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running</span><br></pre></td></tr></table></figure><p>可以看到，所有的系统 Pod 都成功启动了，而刚刚部署的flannel网络插件则在 kube-system 下面新建了一个名叫kube-flannel-ds-amd64-lkf2f的 Pod，一般来说，这些 Pod 就是容器网络插件在每个节点上的控制组件。<br> Kubernetes 支持容器网络插件，使用的是一个名叫 CNI 的通用接口，它也是当前容器网络的事实标准，市面上的所有容器网络开源项目都可以通过 CNI 接入 Kubernetes，比如 Flannel、Calico、Canal、Romana 等等，它们的部署方式也都是类似的“一键部署”。</p><p>至此，Kubernetes 的 Master 节点就部署完成了。如果只需要一个单节点的 Kubernetes，现在你就可以使用了。不过，在默认情况下，Kubernetes 的 Master 节点有污点 (taint) 存在是不能运行用户 Pod 的。可以通过以下步骤删除污点。而<strong>NoSchedule</strong>这个污点仅影响调度过程，对现存 Pod 无影响。</p><p>Taints 的删除和添加，正常部署无需操作，默认即可。</p><p>Ⅰ、查看 Taints</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node k8s-master |grep Taints</span><br><span class="line">Taints:             node-role.kubernetes.io/master:NoSchedule</span><br></pre></td></tr></table></figure><p>Ⅱ、删除这个 Taints</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes k8s-master node-role.kubernetes.io/master=:NoSchedule-</span><br></pre></td></tr></table></figure><p>Ⅲ、添加这样的 Taints</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes k8s-master node-role.kubernetes.io/master=:NoSchedule</span><br></pre></td></tr></table></figure><h3 id="部署node节点">部署node节点</h3><p>Kubernetes 的工作节点与Master节点几乎是相同的，它们运行着的都是一个 kubelet 组件。唯一的区别在于，在 kubeadm init 的过程中，kubelet 启动后，Master 节点上还会自动运行 kube-apiserver、kube-scheduler、kube-controller-manger 这三个系统 Pod。<br> 在 k8s-node1 和 k8s-node2 上分别执行如下命令，将其注册到集群中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 执行以下命令将节点接入集群</span><br><span class="line">kubeadm join 10.10.10.31:6443 --token 67kq55.8hxoga556caxty7s \</span><br><span class="line">    --discovery-token-ca-cert-hash ha256:7d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69</span><br><span class="line"></span><br><span class="line"># 如果执行kubeadm init时没有记录下加入集群的命令，可以通过以下命令重新创建</span><br><span class="line"># --ttl 10m 生成10分钟有效期的token。</span><br><span class="line"># https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/</span><br><span class="line">kubeadm token create --ttl 10m --print-join-command</span><br></pre></td></tr></table></figure><p>在k8s-node1上执行kubeadm join ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node1 ~]# kubeadm join 10.10.10.31:6443 --token 67kq55.8hxoga556caxty7s \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:7d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">......</span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the master to see this node join the cluster.</span><br></pre></td></tr></table></figure><p>重复执行以上操作将k8s-node2也加进去。</p><p>修改节点标签</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes k8s-node1 node-role.kubernetes.io/node=</span><br><span class="line">kubectl label nodes k8s-node2 node-role.kubernetes.io/node=</span><br></pre></td></tr></table></figure><p>然后根据提示，我们可以通过 kubectl get nodes 查看节点的状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl get nodes</span><br><span class="line">NAME         STATUS   ROLES    AGE    VERSION</span><br><span class="line">k8s-master   Ready    master   45m   v1.16.2</span><br><span class="line">k8s-node1    Ready    node     45m   v1.16.2</span><br><span class="line">k8s-node2    Ready    node     45m   v1.16.2</span><br></pre></td></tr></table></figure><p>nodes状态全部为ready，由于每个节点都需要启动若干组件，如果node节点的状态是 NotReady，可以查看所有节点pod状态，确保所有pod成功拉取到镜像并处于running状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl get pod --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    ......</span><br><span class="line">kube-system   coredns-78d4cf999f-7jdx7             1/1     Running</span><br><span class="line">kube-system   coredns-78d4cf999f-s6mhk             1/1     Running</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running</span><br><span class="line">kube-system   kube-flannel-ds-amd64-d2r8p          1/1     Running</span><br><span class="line">kube-system   kube-flannel-ds-amd64-d85c6          1/1     Running</span><br><span class="line">kube-system   kube-flannel-ds-amd64-lkf2f          1/1     Running</span><br><span class="line">kube-system   kube-proxy-k8jx8                     1/1     Running</span><br><span class="line">kube-system   kube-proxy-n95ck                     1/1     Running</span><br><span class="line">kube-system   kube-proxy-przwf                     1/1     Running</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running</span><br></pre></td></tr></table></figure><p>测试集群各个组件<br> 首先验证kube-apiserver, kube-controller-manager, kube-scheduler, pod network 是否正常：<br> 部署一个 Nginx Deployment，包含2个Pod 副本<br> 参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">https://kubernetes.io/docs/concepts/workloads/controllers/deployment/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl create deployment nginx --image=nginx:alpine</span><br><span class="line">deployment.apps/nginx created</span><br><span class="line">[centos@k8s-master ~]$ kubectl scale deployment nginx --replicas=2</span><br><span class="line">deployment.extensions/nginx scaled</span><br><span class="line">[centos@k8s-master ~]#</span><br></pre></td></tr></table></figure><p>验证Nginx Pod是否正确运行，并且会分配10.244.开头的集群IP</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl get pods -l app=nginx -o wide</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE  ......</span><br><span class="line">nginx-54458cd494-p2qgx   1/1     Running   0          111s</span><br><span class="line">nginx-54458cd494-sdlm7   1/1     Running   0          103s</span><br></pre></td></tr></table></figure><p>再验证一下kube-proxy是否正常：</p><p>以 NodePort 方式对外提供服务（也是外部流量引入集群内部的方法）<br> 参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/">https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line">service/nginx exposed</span><br><span class="line">[centos@k8s-master ~]$ kubectl get services nginx</span><br><span class="line">NAME    TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">nginx   NodePort   10.108.17.2   &lt;none&gt;        80:30670/TCP   12s</span><br></pre></td></tr></table></figure><p>可以通过任意 NodeIP:Port 在集群外部访问这个服务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# curl 10.10.10.31:30670</span><br><span class="line">[centos@k8s-master ~]# curl 10.10.10.32:30670</span><br><span class="line">[centos@k8s-master ~]# curl 10.10.10.33:30670</span><br></pre></td></tr></table></figure><h3 id="kube-proxy开启ipvs">kube-proxy开启ipvs</h3><p>修改ConfigMap的kube-system/kube-proxy中的config.conf，mode: “ipvs”。</p><p>如果此前已经开启则无需操作，使用 <code>curl localhost:10249/proxyMode</code>命令可查看，如果要更换为iptables ，则在ConfigMap中修改：mode: “” 为空即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl edit cm kube-proxy -n kube-system</span><br></pre></td></tr></table></figure><p>之后重启各个节点上的kube-proxy pod：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl get pod -n kube-system | grep kube-proxy | awk &#x27;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&#x27;</span><br><span class="line">pod &quot;kube-proxy-2w9sh&quot; deleted</span><br><span class="line">pod &quot;kube-proxy-gw4lx&quot; deleted</span><br><span class="line">pod &quot;kube-proxy-thv4c&quot; deleted</span><br><span class="line">[centos@k8s-master ~]# kubectl get pod -n kube-system | grep kube-proxy</span><br><span class="line">kube-proxy-6qlgv                        1/1     Running   0          65s</span><br><span class="line">kube-proxy-fdtjd                        1/1     Running   0          47s</span><br><span class="line">kube-proxy-m8zkx                        1/1     Running   0          52s</span><br></pre></td></tr></table></figure><p>查看日志：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]# kubectl -n kube-system  logs kube-proxy-dpx74</span><br><span class="line">I1213 09:50:15.414493       1 server_others.go:189] Using ipvs Proxier.</span><br><span class="line">W1213 09:50:15.414908       1 proxier.go:365] IPVS scheduler not specified, use rr by default</span><br><span class="line">I1213 09:50:15.415021       1 server_others.go:216] Tearing down inactive rules.</span><br><span class="line">I1213 09:50:15.461658       1 server.go:464] Version: v1.13.0</span><br><span class="line">I1213 09:50:15.467827       1 conntrack.go:52] Setting nf_conntrack_max to 131072</span><br><span class="line">I1213 09:50:15.467997       1 config.go:202] Starting service config controller</span><br><span class="line">I1213 09:50:15.468010       1 controller_utils.go:1027] Waiting for caches to sync for service config </span><br><span class="line">......</span><br><span class="line"># 或者使用命令，返回ipvs也说明启用ipvs</span><br><span class="line">curl localhost:10249/proxyMode</span><br></pre></td></tr></table></figure><p>日志中打印出了 Using ipvs Proxier，说明 ipvs 模式已经开启。</p><p>移除节点和集群<br> kubernetes集群移除节点<br> 以移除k8s-node2节点为例，在Master节点上运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl drain k8s-node2 --delete-local-data --force --ignore-daemonsets</span><br><span class="line">kubectl delete node k8s-node2</span><br></pre></td></tr></table></figure><p>上面两条命令执行完成后，在k8s-node2节点执行清理命令，重置kubeadm的安装状态：<br> kubeadm reset<br> 在master上删除node并不会清理k8s-node2运行的容器，需要在删除节点上面手动运行清理命令。<br> 如果你想重新配置集群，使用新的参数重新运行kubeadm init或者kubeadm join即可。</p><p>至此3个节点的集群搭建完成，后续可以继续添加node节点，或者部署dashboard、helm包管理工具、EFK日志系统、Prometheus Operator监控系统、rook+ceph存储系统等组件。</p><p>参考：</p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wc1695040842/article/details/105841329">https://blog.csdn.net/wc1695040842/article/details/105841329</a></p><div id="reword-out"><div id="reward-btn"> 打赏</div></div></div><div class="declare"><ul class="post-copyright"><li><i class="ri-copyright-line"></i> <strong>版权声明：</strong> 本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！</li></ul></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li></ul></footer></div><nav class="article-nav"> <a href="/2021/06/nginx-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%E7%9A%84%E7%9B%B8%E5%85%B3%E8%AF%B7%E6%B1%82%E5%A4%B4%E8%AE%BE%E7%BD%AE/index.html" class="article-nav-link"><strong class="article-nav-caption">上一篇</strong><div class="article-nav-title"> nginx 反向代理配置的相关请求头设置</div></a> <a href="/2021/05/ssh-%E5%85%8D%E5%AF%86%E9%80%9A%E9%81%93%E7%99%BB%E5%BD%95%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/index.html" class="article-nav-link"><strong class="article-nav-caption">下一篇</strong><div class="article-nav-title">ssh 免密通道登录及常见问题</div></a></nav><script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script><div id="twikoo" class="twikoo"></div><script>twikoo.init({envId:""})</script></article></section><footer class="footer"><div class="outer"><ul><li> Copyrights &copy; 2018-2024<i class="ri-heart-fill heart_icon"></i> Outsrkem</li></ul><ul><li></li></ul><ul><li><span><span><i class="ri-user-3-fill"></i> 访问人数:<span id="busuanzi_value_site_uv"></span></span> <span class="division">|</span><span><i class="ri-eye-fill"></i> 浏览次数:<span id="busuanzi_value_page_pv"></span></span></span></li></ul><ul></ul><ul></ul><ul><li><script type="text/javascript" src="https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914"></script></li></ul></div></footer></main><div class="float_btns"><div class="totop" id="totop"><i class="ri-arrow-up-line"></i></div><div class="todark" id="todark"><i class="ri-moon-line"></i></div></div><aside class="sidebar on"> <button class="navbar-toggle"></button><nav class="navbar"><div class="logo"> <a href="/"><img src="/images/ayer-side.svg" alt="Outsrkem"></a></div><ul class="nav nav-main"><li class="nav-item"> <a class="nav-item-link" href="/index.html">主页</a></li><li class="nav-item"> <a class="nav-item-link" href="/archives/index.html">归档</a></li><li class="nav-item"> <a class="nav-item-link" href="/categories/index.html">分类</a></li><li class="nav-item"> <a class="nav-item-link" href="/tags/index.html">标签</a></li><li class="nav-item"> <a class="nav-item-link" href="/friends/index.html">友链</a></li><li class="nav-item"> <a class="nav-item-link" href="/about/index.html">关于</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><a class="nav-item-link nav-item-search" title="搜索"><i class="ri-search-line"></i></a></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"> <input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><div id="mask"></div> <div id="reward"><span class="close"><i class="ri-close-line"></i></span><p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p><div class="reward-box"><div class="reward-item"> <img class="reward-img" src="/images/alipay.jpg"> <span class="reward-type">支付宝</span></div><div class="reward-item"> <img class="reward-img" src="/images/wechat.jpg"> <span class="reward-type">微信</span></div></div></div><script src="/js/jquery-3.6.0.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,scrollContainer:"main",positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"><script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script><script src="/dist/main.js"></script><div class="pswp" tabindex="-1" role="dialog" aria-hidden="true"><div class="pswp__bg"></div><div class="pswp__scroll-wrap"><div class="pswp__container"><div class="pswp__item"></div><div class="pswp__item"></div><div class="pswp__item"></div></div><div class="pswp__ui pswp__ui--hidden"><div class="pswp__top-bar"><div class="pswp__counter"></div> <button class="pswp__button pswp__button--close" title="Close (Esc)"></button> <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button> <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button> <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class="pswp__preloader"><div class="pswp__preloader__icn"><div class="pswp__preloader__cut"><div class="pswp__preloader__donut"></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class="pswp__share-tooltip"></div></div> <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button> <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class="pswp__caption"><div class="pswp__caption__center"></div></div></div></div></div><link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css"><script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script><script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script><script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script><script src="/js/busuanzi-2.3.pure.min.js"></script><link rel="stylesheet" href="/css/clipboard.css"><script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script><script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script><script>window.mermaid&&mermaid.initialize({theme:"forest"})</script></div></body>